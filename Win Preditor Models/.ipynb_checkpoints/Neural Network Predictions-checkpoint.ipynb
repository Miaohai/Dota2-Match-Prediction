{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information\n",
    "\n",
    "In this notebook, we are going to predict win rate using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To simplify your navigation through this kernel:\n",
    "    Main data exploration:\n",
    "        1: Splitting and preparing datasets to test:\n",
    "        2: Predictive Modelling (Neural Network)\n",
    "        3: Evaluate model performance\n",
    "            -Classification Accuracy\n",
    "            -AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(r\"C:\\Users\\chena\\Desktop\\dota-2-matches\\code\\all_csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "matches = pd.read_csv('match.csv')\n",
    "y = matches['radiant_win'].apply(lambda win: 1 if win else 0)\n",
    "classes = ['Dire Win', 'Radiant Win']\n",
    "X = pd.read_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1: Splitting and preparing datasets to test:\n",
    "1. Hero Selection + Counter rate only\n",
    "2. Hero Selection + Synergy only\n",
    "3. Hero Selection + Synergy + Counter Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_Abaddon</th>\n",
       "      <th>radiant_Alchemist</th>\n",
       "      <th>radiant_Ancient Apparition</th>\n",
       "      <th>radiant_Anti-Mage</th>\n",
       "      <th>radiant_Axe</th>\n",
       "      <th>radiant_Bane</th>\n",
       "      <th>radiant_Batrider</th>\n",
       "      <th>radiant_Beastmaster</th>\n",
       "      <th>radiant_Bloodseeker</th>\n",
       "      <th>radiant_Bounty Hunter</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_Visage</th>\n",
       "      <th>dire_Warlock</th>\n",
       "      <th>dire_Weaver</th>\n",
       "      <th>dire_Windranger</th>\n",
       "      <th>dire_Winter Wyvern</th>\n",
       "      <th>dire_Witch Doctor</th>\n",
       "      <th>dire_Wraith King</th>\n",
       "      <th>dire_Zeus</th>\n",
       "      <th>diff</th>\n",
       "      <th>df_between_hero_synergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.893963</td>\n",
       "      <td>0.119532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>-0.062968</td>\n",
       "      <td>-1.558533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>-1.308931</td>\n",
       "      <td>-0.779188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.138878</td>\n",
       "      <td>-0.915655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>1.932924</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>0.848292</td>\n",
       "      <td>-0.321797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_Abaddon  radiant_Alchemist  radiant_Ancient Apparition  \\\n",
       "0        -0.186807          -0.331961                   -0.269303   \n",
       "1        -0.186807          -0.331961                   -0.269303   \n",
       "2        -0.186807          -0.331961                   -0.269303   \n",
       "3        -0.186807          -0.331961                   -0.269303   \n",
       "4        -0.186807          -0.331961                   -0.269303   \n",
       "\n",
       "   radiant_Anti-Mage  radiant_Axe  radiant_Bane  radiant_Batrider  \\\n",
       "0          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "1          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "2          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "3          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "4          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "\n",
       "   radiant_Beastmaster  radiant_Bloodseeker  radiant_Bounty Hunter  ...  \\\n",
       "0            -0.114676            -0.175803              -0.268062  ...   \n",
       "1            -0.114676            -0.175803              -0.268062  ...   \n",
       "2            -0.114676            -0.175803              -0.268062  ...   \n",
       "3            -0.114676            -0.175803              -0.268062  ...   \n",
       "4            -0.114676            -0.175803              -0.268062  ...   \n",
       "\n",
       "   dire_Visage  dire_Warlock  dire_Weaver  dire_Windranger  \\\n",
       "0    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "1    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "2    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "3    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "4    -0.103506     -0.139616    -0.163512         1.932924   \n",
       "\n",
       "   dire_Winter Wyvern  dire_Witch Doctor  dire_Wraith King  dire_Zeus  \\\n",
       "0           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "1           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "2           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "3           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "4           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "\n",
       "       diff  df_between_hero_synergy  \n",
       "0  0.893963                 0.119532  \n",
       "1 -0.062968                -1.558533  \n",
       "2 -1.308931                -0.779188  \n",
       "3  0.138878                -0.915655  \n",
       "4  0.848292                -0.321797  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we import python libraries which we will use for modelling and visualing the final model:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=pd.DataFrame(scaler.transform(X),columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_Abaddon</th>\n",
       "      <th>radiant_Alchemist</th>\n",
       "      <th>radiant_Ancient Apparition</th>\n",
       "      <th>radiant_Anti-Mage</th>\n",
       "      <th>radiant_Axe</th>\n",
       "      <th>radiant_Bane</th>\n",
       "      <th>radiant_Batrider</th>\n",
       "      <th>radiant_Beastmaster</th>\n",
       "      <th>radiant_Bloodseeker</th>\n",
       "      <th>radiant_Bounty Hunter</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_Viper</th>\n",
       "      <th>dire_Visage</th>\n",
       "      <th>dire_Warlock</th>\n",
       "      <th>dire_Weaver</th>\n",
       "      <th>dire_Windranger</th>\n",
       "      <th>dire_Winter Wyvern</th>\n",
       "      <th>dire_Witch Doctor</th>\n",
       "      <th>dire_Wraith King</th>\n",
       "      <th>dire_Zeus</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.893963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>-0.062968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>-1.308931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>5.137826</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.138878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>1.932924</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>0.848292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_Abaddon  radiant_Alchemist  radiant_Ancient Apparition  \\\n",
       "0        -0.186807          -0.331961                   -0.269303   \n",
       "1        -0.186807          -0.331961                   -0.269303   \n",
       "2        -0.186807          -0.331961                   -0.269303   \n",
       "3        -0.186807          -0.331961                   -0.269303   \n",
       "4        -0.186807          -0.331961                   -0.269303   \n",
       "\n",
       "   radiant_Anti-Mage  radiant_Axe  radiant_Bane  radiant_Batrider  \\\n",
       "0          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "1          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "2          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "3          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "4          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "\n",
       "   radiant_Beastmaster  radiant_Bloodseeker  radiant_Bounty Hunter  ...  \\\n",
       "0            -0.114676            -0.175803              -0.268062  ...   \n",
       "1            -0.114676            -0.175803              -0.268062  ...   \n",
       "2            -0.114676            -0.175803              -0.268062  ...   \n",
       "3            -0.114676            -0.175803              -0.268062  ...   \n",
       "4            -0.114676            -0.175803              -0.268062  ...   \n",
       "\n",
       "   dire_Viper  dire_Visage  dire_Warlock  dire_Weaver  dire_Windranger  \\\n",
       "0   -0.194635    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "1   -0.194635    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "2   -0.194635    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "3    5.137826    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "4   -0.194635    -0.103506     -0.139616    -0.163512         1.932924   \n",
       "\n",
       "   dire_Winter Wyvern  dire_Witch Doctor  dire_Wraith King  dire_Zeus  \\\n",
       "0           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "1           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "2           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "3           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "4           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "\n",
       "       diff  \n",
       "0  0.893963  \n",
       "1 -0.062968  \n",
       "2 -1.308931  \n",
       "3  0.138878  \n",
       "4  0.848292  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X.iloc[:,0:223]\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_Abaddon</th>\n",
       "      <th>radiant_Alchemist</th>\n",
       "      <th>radiant_Ancient Apparition</th>\n",
       "      <th>radiant_Anti-Mage</th>\n",
       "      <th>radiant_Axe</th>\n",
       "      <th>radiant_Bane</th>\n",
       "      <th>radiant_Batrider</th>\n",
       "      <th>radiant_Beastmaster</th>\n",
       "      <th>radiant_Bloodseeker</th>\n",
       "      <th>radiant_Bounty Hunter</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_Viper</th>\n",
       "      <th>dire_Visage</th>\n",
       "      <th>dire_Warlock</th>\n",
       "      <th>dire_Weaver</th>\n",
       "      <th>dire_Windranger</th>\n",
       "      <th>dire_Winter Wyvern</th>\n",
       "      <th>dire_Witch Doctor</th>\n",
       "      <th>dire_Wraith King</th>\n",
       "      <th>dire_Zeus</th>\n",
       "      <th>df_between_hero_synergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.119532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>-1.558533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>-0.779188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>5.137826</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>-0.915655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194635</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>1.932924</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>-0.321797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_Abaddon  radiant_Alchemist  radiant_Ancient Apparition  \\\n",
       "0        -0.186807          -0.331961                   -0.269303   \n",
       "1        -0.186807          -0.331961                   -0.269303   \n",
       "2        -0.186807          -0.331961                   -0.269303   \n",
       "3        -0.186807          -0.331961                   -0.269303   \n",
       "4        -0.186807          -0.331961                   -0.269303   \n",
       "\n",
       "   radiant_Anti-Mage  radiant_Axe  radiant_Bane  radiant_Batrider  \\\n",
       "0          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "1          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "2          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "3          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "4          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "\n",
       "   radiant_Beastmaster  radiant_Bloodseeker  radiant_Bounty Hunter  ...  \\\n",
       "0            -0.114676            -0.175803              -0.268062  ...   \n",
       "1            -0.114676            -0.175803              -0.268062  ...   \n",
       "2            -0.114676            -0.175803              -0.268062  ...   \n",
       "3            -0.114676            -0.175803              -0.268062  ...   \n",
       "4            -0.114676            -0.175803              -0.268062  ...   \n",
       "\n",
       "   dire_Viper  dire_Visage  dire_Warlock  dire_Weaver  dire_Windranger  \\\n",
       "0   -0.194635    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "1   -0.194635    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "2   -0.194635    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "3    5.137826    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "4   -0.194635    -0.103506     -0.139616    -0.163512         1.932924   \n",
       "\n",
       "   dire_Winter Wyvern  dire_Witch Doctor  dire_Wraith King  dire_Zeus  \\\n",
       "0           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "1           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "2           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "3           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "4           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "\n",
       "   df_between_hero_synergy  \n",
       "0                 0.119532  \n",
       "1                -1.558533  \n",
       "2                -0.779188  \n",
       "3                -0.915655  \n",
       "4                -0.321797  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = X.drop(\"diff\", axis=1)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_Abaddon</th>\n",
       "      <th>radiant_Alchemist</th>\n",
       "      <th>radiant_Ancient Apparition</th>\n",
       "      <th>radiant_Anti-Mage</th>\n",
       "      <th>radiant_Axe</th>\n",
       "      <th>radiant_Bane</th>\n",
       "      <th>radiant_Batrider</th>\n",
       "      <th>radiant_Beastmaster</th>\n",
       "      <th>radiant_Bloodseeker</th>\n",
       "      <th>radiant_Bounty Hunter</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_Visage</th>\n",
       "      <th>dire_Warlock</th>\n",
       "      <th>dire_Weaver</th>\n",
       "      <th>dire_Windranger</th>\n",
       "      <th>dire_Winter Wyvern</th>\n",
       "      <th>dire_Witch Doctor</th>\n",
       "      <th>dire_Wraith King</th>\n",
       "      <th>dire_Zeus</th>\n",
       "      <th>diff</th>\n",
       "      <th>df_between_hero_synergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.893963</td>\n",
       "      <td>0.119532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>-0.062968</td>\n",
       "      <td>-1.558533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>-1.308931</td>\n",
       "      <td>-0.779188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>-0.517351</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>-0.221033</td>\n",
       "      <td>0.138878</td>\n",
       "      <td>-0.915655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186807</td>\n",
       "      <td>-0.331961</td>\n",
       "      <td>-0.269303</td>\n",
       "      <td>-0.319718</td>\n",
       "      <td>-0.219135</td>\n",
       "      <td>-0.162088</td>\n",
       "      <td>-0.100301</td>\n",
       "      <td>-0.114676</td>\n",
       "      <td>-0.175803</td>\n",
       "      <td>-0.268062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103506</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.163512</td>\n",
       "      <td>1.932924</td>\n",
       "      <td>-0.287529</td>\n",
       "      <td>-0.28145</td>\n",
       "      <td>-0.290373</td>\n",
       "      <td>4.524206</td>\n",
       "      <td>0.848292</td>\n",
       "      <td>-0.321797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_Abaddon  radiant_Alchemist  radiant_Ancient Apparition  \\\n",
       "0        -0.186807          -0.331961                   -0.269303   \n",
       "1        -0.186807          -0.331961                   -0.269303   \n",
       "2        -0.186807          -0.331961                   -0.269303   \n",
       "3        -0.186807          -0.331961                   -0.269303   \n",
       "4        -0.186807          -0.331961                   -0.269303   \n",
       "\n",
       "   radiant_Anti-Mage  radiant_Axe  radiant_Bane  radiant_Batrider  \\\n",
       "0          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "1          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "2          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "3          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "4          -0.319718    -0.219135     -0.162088         -0.100301   \n",
       "\n",
       "   radiant_Beastmaster  radiant_Bloodseeker  radiant_Bounty Hunter  ...  \\\n",
       "0            -0.114676            -0.175803              -0.268062  ...   \n",
       "1            -0.114676            -0.175803              -0.268062  ...   \n",
       "2            -0.114676            -0.175803              -0.268062  ...   \n",
       "3            -0.114676            -0.175803              -0.268062  ...   \n",
       "4            -0.114676            -0.175803              -0.268062  ...   \n",
       "\n",
       "   dire_Visage  dire_Warlock  dire_Weaver  dire_Windranger  \\\n",
       "0    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "1    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "2    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "3    -0.103506     -0.139616    -0.163512        -0.517351   \n",
       "4    -0.103506     -0.139616    -0.163512         1.932924   \n",
       "\n",
       "   dire_Winter Wyvern  dire_Witch Doctor  dire_Wraith King  dire_Zeus  \\\n",
       "0           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "1           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "2           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "3           -0.287529           -0.28145         -0.290373  -0.221033   \n",
       "4           -0.287529           -0.28145         -0.290373   4.524206   \n",
       "\n",
       "       diff  df_between_hero_synergy  \n",
       "0  0.893963                 0.119532  \n",
       "1 -0.062968                -1.558533  \n",
       "2 -1.308931                -0.779188  \n",
       "3  0.138878                -0.915655  \n",
       "4  0.848292                -0.321797  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Modelling (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Neural Network Model (Based on previous experiences testing, having minimal layers with minimal neurons was more effective than increasing it constantly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()  # input layer\n",
    "model.add(layers.Dense(10, activation='relu', input_shape=(223,)))  \n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "             loss='squared_hinge',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with Hero Selection + Counter only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 37500 samples\n",
      "Epoch 1/10\n",
      "37500/37500 [==============================] - 5s 139us/sample - loss: 0.8490 - accuracy: 0.5646\n",
      "Epoch 2/10\n",
      "37500/37500 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.72 - 4s 106us/sample - loss: 0.5622 - accuracy: 0.7231\n",
      "Epoch 3/10\n",
      "37500/37500 [==============================] - 4s 97us/sample - loss: 0.4713 - accuracy: 0.7755\n",
      "Epoch 4/10\n",
      "37500/37500 [==============================] - 3s 91us/sample - loss: 0.4462 - accuracy: 0.7895\n",
      "Epoch 5/10\n",
      "37500/37500 [==============================] - 4s 100us/sample - loss: 0.4348 - accuracy: 0.7980\n",
      "Epoch 6/10\n",
      "37500/37500 [==============================] - 3s 79us/sample - loss: 0.4240 - accuracy: 0.8025\n",
      "Epoch 7/10\n",
      "37500/37500 [==============================] - 3s 79us/sample - loss: 0.4161 - accuracy: 0.8063\n",
      "Epoch 8/10\n",
      "37500/37500 [==============================] - 4s 98us/sample - loss: 0.4090 - accuracy: 0.8117\n",
      "Epoch 9/10\n",
      "37500/37500 [==============================] - 3s 81us/sample - loss: 0.4027 - accuracy: 0.8151\n",
      "Epoch 10/10\n",
      "37500/37500 [==============================] - 3s 75us/sample - loss: 0.3965 - accuracy: 0.8199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a28500a708>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X1, y, test_size=0.25, random_state=7)\n",
    "#fit model\n",
    "model.fit(x=X_train.values,y=y_train.values, epochs=10)\n",
    "#accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78752\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print (\"Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.846141\n",
      "Recall: 0.800369\n",
      "F1 score: 0.822619\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions\n",
    "predictions = np.where(predictions <= 0, 0, predictions)\n",
    "predictions = np.where(predictions > 0, 1, predictions)\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: tp / (tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with Hero Selection + Synergy only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples\n",
      "Epoch 1/10\n",
      "37500/37500 [==============================] - 3s 79us/sample - loss: 0.9022 - accuracy: 0.5242\n",
      "Epoch 2/10\n",
      "37500/37500 [==============================] - 3s 79us/sample - loss: 0.8767 - accuracy: 0.5368\n",
      "Epoch 3/10\n",
      "37500/37500 [==============================] - 3s 82us/sample - loss: 0.8617 - accuracy: 0.5491\n",
      "Epoch 4/10\n",
      "37500/37500 [==============================] - 3s 80us/sample - loss: 0.8470 - accuracy: 0.5603\n",
      "Epoch 5/10\n",
      "37500/37500 [==============================] - 3s 87us/sample - loss: 0.8355 - accuracy: 0.5670\n",
      "Epoch 6/10\n",
      "37500/37500 [==============================] - 3s 86us/sample - loss: 0.8265 - accuracy: 0.5767\n",
      "Epoch 7/10\n",
      "37500/37500 [==============================] - 3s 87us/sample - loss: 0.8194 - accuracy: 0.5809\n",
      "Epoch 8/10\n",
      "37500/37500 [==============================] - 3s 89us/sample - loss: 0.8133 - accuracy: 0.5882\n",
      "Epoch 9/10\n",
      "37500/37500 [==============================] - 3s 89us/sample - loss: 0.8055 - accuracy: 0.5927\n",
      "Epoch 10/10\n",
      "37500/37500 [==============================] - 3s 85us/sample - loss: 0.7995 - accuracy: 0.5978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a283787708>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X2, y, test_size=0.25, random_state=7)\n",
    "#fit model\n",
    "model.fit(x=X_train.values,y=y_train.values, epochs=10)\n",
    "#accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56496\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print (\"Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.650985\n",
      "Recall: 0.640080\n",
      "F1 score: 0.645486\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions\n",
    "predictions = np.where(predictions <= 0, 0, predictions)\n",
    "predictions = np.where(predictions > 0, 1, predictions)\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: tp / (tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with Hero Selection + Synergy + Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to rerun the model to have input shape of 224 instead of 223\n",
    "model = tf.keras.Sequential()  # input layer\n",
    "model.add(layers.Dense(10, activation='relu', input_shape=(224,)))  \n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "model.add(layers.Dense(30, activation=tf.nn.relu))      # one hidden layer\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "             loss='squared_hinge',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples\n",
      "Epoch 1/10\n",
      "37500/37500 [==============================] - 3s 87us/sample - loss: 0.8358 - accuracy: 0.5651\n",
      "Epoch 2/10\n",
      "37500/37500 [==============================] - 3s 75us/sample - loss: 0.5681 - accuracy: 0.7172\n",
      "Epoch 3/10\n",
      "37500/37500 [==============================] - 3s 73us/sample - loss: 0.4596 - accuracy: 0.7805\n",
      "Epoch 4/10\n",
      "37500/37500 [==============================] - 3s 75us/sample - loss: 0.4220 - accuracy: 0.8004\n",
      "Epoch 5/10\n",
      "37500/37500 [==============================] - 3s 81us/sample - loss: 0.4048 - accuracy: 0.8144\n",
      "Epoch 6/10\n",
      "37500/37500 [==============================] - 3s 80us/sample - loss: 0.3939 - accuracy: 0.8210\n",
      "Epoch 7/10\n",
      "37500/37500 [==============================] - 3s 77us/sample - loss: 0.3874 - accuracy: 0.8242\n",
      "Epoch 8/10\n",
      "37500/37500 [==============================] - 3s 83us/sample - loss: 0.3792 - accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "37500/37500 [==============================] - 3s 83us/sample - loss: 0.3725 - accuracy: 0.8359\n",
      "Epoch 10/10\n",
      "37500/37500 [==============================] - 3s 75us/sample - loss: 0.3669 - accuracy: 0.8390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a283a4f088>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=7)\n",
    "#fit model\n",
    "model.fit(x=X_train.values,y=y_train.values, epochs=10)\n",
    "#accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81192\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print (\"Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.842202\n",
      "Recall: 0.841555\n",
      "F1 score: 0.841879\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions <= 0, 0, predictions)\n",
    "predictions = np.where(predictions > 0, 1, predictions)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: tp / (tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall highest accuracy was when the neural network took in both Counter and Synergy rate. However, based on the accuracy for each factor, it is clear that Counter rate alone had an test data accuracy of ~79% and likely had a bigger impact on the final accuracy of ~81% at the end compared to Synergy rate which had a test data accuracy of ~ 57%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "AUC - Test Set: 92.73%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, :]\n",
    "\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC - Test Set: %.2f%%' % (auc*100))\n",
    "\n",
    "# # calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# # plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# # plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
